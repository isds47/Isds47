{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c517ba875fbc0cd184268049c8609522",
     "grade": false,
     "grade_id": "cell-8f45287b5a246de7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mandatory Assignment 1\n",
    "\n",
    "This is the second of three mandatory assignments which must be completed during the course. Note that you only need to pass 2 out of 3 assignments to be eligible for the exam.\n",
    "\n",
    "\n",
    "First some practical information:\n",
    "\n",
    "* When is the assignment due?: **23:59, Friday, August 14, 2020.**\n",
    "* Should i work with my group?: **Yes**. In particular, you should **only hand in 1 assignment per group**.\n",
    "\n",
    "The assignment consists of problems from some of the exercise sets that you have solved so far. Some exercises are modified a little to better suit the structure of the assignment. \n",
    "\n",
    "**Note**: It is important that you submit your edited version of THIS [notebook](https://fileinfo.com/extension/ipynb#:~:text=An%20IPYNB%20file%20is%20a,Python%20language%20and%20their%20data.) as a .ipynb file and nothing else. Do not copy your answers into another notebook that you have made. Do not submit your answers as a pdf. Do not convert the notebook to json and then submit that etc. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e57a58220baf08616abfa857e653c538",
     "grade": false,
     "grade_id": "cell-bc2367dff4ff3524",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 3:\n",
    "\n",
    "> **Ex. 3.2.1:**: Show the first five rows of the titanic dataset. What information is in the dataset? Use a barplot to show the probability of survival for men and women within each passenger class. Can you make a boxplot showing the same information (why/why not?). Write _three sentences_ for this question. \n",
    ">\n",
    "> > _Hint:_ https://seaborn.pydata.org/generated/seaborn.barplot.html, specifically the `hue` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fd42dcee0a00052e8e482aef177a7ca",
     "grade": true,
     "grade_id": "cell-65ba6c136759c47e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aeba0c4874dca1f22456f30940246e5b",
     "grade": false,
     "grade_id": "cell-59488e40ebf2f946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.2.2:** Using the iris flower dataset, draw a scatterplot of sepal length and petal length. Include a second order polynomial fitted to the data. Add a title to the plot and rename the axis labels to `sepal length` and `sepal width`.\n",
    "> _Write 3 sentences:_ Is this a meaningful way to display the data? What could we do differently?\n",
    ">\n",
    "> For a better understanding of the dataset this image might be useful:\n",
    "> <img src=\"iris_pic.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    ">\n",
    ">> _Hint:_ use the `.regplot` method from seaborn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6d0f5b94be36ff56860be2f55836915",
     "grade": true,
     "grade_id": "cell-da18db88eaa1f744",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c37b469b80844d328b6ed4438269eba",
     "grade": false,
     "grade_id": "cell-2a6cf101dd1893ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.2.3:** Combine the two of the figures you created above into a two-panel figure similar to the one shown here:\n",
    "> <img src=\"Example.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    ">\n",
    "> Save the figure as a png file in this on your computer named `two_plots.png`. \n",
    ">> _Hint:_ See [this question](https://stackoverflow.com/questions/41384040/subplot-for-seaborn-boxplot) on stackoverflow for inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b46a72df9de9908ecc2c7fa154edb3f9",
     "grade": true,
     "grade_id": "cell-6cafe530cd2ff474",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2319fa1a3b36c28e97c36f0c53c8b41",
     "grade": false,
     "grade_id": "cell-e28611963fcc9e39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 3.2.4:** Use [pairplot with hue](https://seaborn.pydata.org/generated/seaborn.pairplot.html) to create a figure that clearly shows how the different species vary across measurements. Change the color palette and remove the shading from the density plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c24cef1e2ed266e36e4cebe2cd61061",
     "grade": true,
     "grade_id": "cell-85e216ea49a4d32c",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84a3640a6987c45c3f460a952266b015",
     "grade": false,
     "grade_id": "cell-d347f9c3c3952e04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 4:\n",
    "\n",
    "We continue with the exercise that analyzes NOAA data. This time we are going to **read the weather data from a csv file** located in this assignment directory instead of trying to request the website. The file is called `'weather_data_1870-1875.csv'` and consists of weather data for the period 1870-1875. Specifically, the csv file contains a dataframe which has been constructed by concatenating the _non-processed_ data from 1870-1875."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31371dbc52c6ff55625399e22ef62c6e",
     "grade": false,
     "grade_id": "cell-a5d456315fd7e75e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 4.1.1:** The code below runs through some of the steps we completed in exercise 4.1.1 in Module 4. As we are not going to request the website but load the data from a csv file your task is to **rewrite parts of the function**. Rename the function to `process_weather` instead of `load_weather`. The function should now  take a `dataframe` as input. The function should still run through the same processing steps although you should consider whether `df_weather.iloc[:, :4]` is necessary for the weather data loaded from  the csv file. The doc string should also be rewritten. After having rewritten the function, load the weather data from `'weather_data_1870-1875.csv'` into a pandas dataframe, apply the `load_weather` function  to this dataframe and store the result in the variable `df_weather_period`.   \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "def load_weather(year):\n",
    "    \n",
    "    '''\n",
    "    This functions loads the data for selected year and then structures and cleans it.\n",
    "    - Structuring includes removing unused columns, renaming and selecting only observations \n",
    "    of maximum temperature. \n",
    "    - Cleaning includes inserting missing decimal, sorting and resetting index.\n",
    "    '''\n",
    "    url = f\"ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/{year}.csv.gz\"\n",
    "    \n",
    "    # loads the data\n",
    "    df_weather = pd.read_csv(url, header=None)\\\n",
    "                    .iloc[:,:4] \n",
    "    \n",
    "    # structure and clean data using methods chaining\n",
    "    # note that the original columns now are strings when loading the csv file\n",
    "    # and not integers as when downloading the data\n",
    "    df_out = \\\n",
    "        df_weather\\\n",
    "            .rename(columns={'0': 'station', '1': 'datetime', '2': 'obs_type', '3': 'obs_value'})\\\n",
    "            .query(\"obs_type == 'TMAX'\")\\\n",
    "            .assign(obs_value=lambda df: df['obs_value']/10)\\\n",
    "            .sort_values(by=['station', 'datetime'])\\\n",
    "            .reset_index(drop=True)\\\n",
    "            .copy() \n",
    "\n",
    "    # area process\n",
    "    df_out['area'] = df_out['station'].str[0:2]\n",
    "    \n",
    "    # datetime process\n",
    "    df_out['datetime_dt'] = pd.to_datetime(df_out['datetime'], format = '%Y%m%d')\n",
    "    df_out['month'] = df_out['datetime_dt'].dt.month\n",
    "    df_out['year'] = df_out['datetime_dt'].dt.year\n",
    "    \n",
    "    return df_out\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c47644998dfea92678c416706adff8a5",
     "grade": false,
     "grade_id": "cell-b75fed704ead2cba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e04676686ce0f87074ec3da5f672c9a1",
     "grade": true,
     "grade_id": "cell-d09a2ec589f954b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert any(df_weather_period.station == process_weather(pd.read_csv('weather_data_1870-1875.csv')).station)\n",
    "assert any(df_weather_period.columns.values == ['station', 'datetime', 'obs_type', 'area', \n",
    "                                                'obs_value', 'datetime_dt', 'month', 'year'])\n",
    "assert len(df_weather_period) == 132317\n",
    "assert round(df_weather_period.obs_value.mean()) == 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ac80c5aed9a34468343198bc4eca629",
     "grade": false,
     "grade_id": "cell-f70158d49468d4c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 4.1.1.1 (Not seen in module 4):** Try to plot the observations value of `df_weather_period` by running `df_weather_period.obs_value.plot()`. Something seems off, right? Now try to inspect the problematic subset of the dataframe by running `df_weather_period[df_weather_period.obs_value < -50]`. What can these observations be characterized as? Drop these three observations from `df_weather_period`, reset the index and drop the column with the old index. Store the dataframe back into the variable `df_weather_period`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea8cad305ef02a124cdc806dc67b1dae",
     "grade": false,
     "grade_id": "cell-9847b54d261d05cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "455ea80ef0233e4dcb984d561fb46625",
     "grade": true,
     "grade_id": "cell-243d261eec02f4b9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df_weather_period[df_weather_period.obs_value < -50]) == 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f38ee104bd7cee0590b6f7d686dec4ae",
     "grade": false,
     "grade_id": "cell-a6b73e84fd1e6ab6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 4.1.3:** \n",
    "Continuing with the `df_weather_period` from last exercise, convert the `area` column to a categorical variable. \n",
    "Transform the `obs_value` column from a continuous to a categorical variable by partitioning it into `3` intervals. Call this new column for `obs_value_cat`.  This can be done using the `pd.cut()` method of pandas. \n",
    "Make another column with  `obs_value` as a categorical variable but this time label the 3 intervals as `[\"cold\", \"medium\", \"hot\"]`. This can be done by specifying the `labels` parameter in the `pd.cut()` method of pandas. Call this new column for `obs_value_cat_labeled`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "764a0f0076c0e3c10001fd176b4a7498",
     "grade": false,
     "grade_id": "cell-0fe64cf676f54c78",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "836097e9bdf952b372f1e6db88efefa1",
     "grade": true,
     "grade_id": "cell-232c5d319bcb0993",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sorted(df_weather_period.obs_value_cat.value_counts()) == [7594, 38878, 85842]\n",
    "assert sorted(df_weather_period.obs_value_cat_labeled.value_counts()) == [7594, 38878, 85842]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05175118e69f0d534b10f80601bb5178",
     "grade": false,
     "grade_id": "cell-059e7b61d9fd84a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 5:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "313b5d1e6c291b78f45b95b13f0c0834",
     "grade": false,
     "grade_id": "cell-dc7c9af39bbc941f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 5.1.2:** Compute the mean maximum daily temperature for each month-year pair on the dataframe `df_weather_period` from last exercise by using the `groupby` and `mean` methods. Store the results in the variable `tmax_mean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "986c3d35b76eada9812163bff00cd0f2",
     "grade": false,
     "grade_id": "cell-03cbeb53b0aff2bb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "081622fb681c225b77b42b1a8da9ff79",
     "grade": true,
     "grade_id": "cell-5e5ae85a8b9a41e8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(tmax_mean.sum()) ==  1017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5107d6ca47a9f4a362c52b55157074ff",
     "grade": false,
     "grade_id": "cell-06207d8e5eb39706",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 5.1.3:** Plot the monthly max,min, mean, first and third quartiles for maximum temperature for the station with ID _'ITE00100550'_ from `df_weather_period`.\n",
    "\n",
    "> *Hint*: the method `describe` computes all these measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b58ff10a12a9c352dc469e17333e0a82",
     "grade": true,
     "grade_id": "cell-2fa6e05b52415d68",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5af542ac45f10bc7506cf2d8a08d27a",
     "grade": false,
     "grade_id": "cell-536770b494f89924",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 5.1.4:** Use the station location data, which is located in this directory, to merge station locations onto `df_weather_period`. The file with station location data is called  `ghcnd-stations.txt`.  Store the result in the variable `final_data`. \n",
    "\n",
    "> _Hint:_ The location data have the folllowing format, \n",
    "\n",
    "```\n",
    "------------------------------\n",
    "Variable   Columns   Type\n",
    "------------------------------\n",
    "ID            1-11   Character\n",
    "LATITUDE     13-20   Real\n",
    "LONGITUDE    22-30   Real\n",
    "ELEVATION    32-37   Real\n",
    "STATE        39-40   Character\n",
    "NAME         42-71   Character\n",
    "GSN FLAG     73-75   Character\n",
    "HCN/CRN FLAG 77-79   Character\n",
    "WMO ID       81-85   Character\n",
    "------------------------------\n",
    "```\n",
    "\n",
    "> *Hint*: The station information has fixed width format - does there exist a pandas reader for that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "773830bfa689207cac91e81f4ac970ac",
     "grade": false,
     "grade_id": "cell-dbf210d3760e0e0a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb8d9c9045b9002e6f46a386e716c2d3",
     "grade": true,
     "grade_id": "cell-161d2af41f2ac693",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(final_data.lon.mean()) == -17 \n",
    "assert round(final_data.lat.mean()) == 43\n",
    "assert round(final_data.elevation.mean())  == 248"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24f124dd32484722aaa61b0aaa7a6d93",
     "grade": false,
     "grade_id": "cell-c79c0e1d03d847e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 6\n",
    "\n",
    "> **Ex. 6.1.2.:** Use the `request` module to collect the first page of job postings and unpack the relevant `json` data into a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1ad456807d0daf372d3a01858eeda7a",
     "grade": false,
     "grade_id": "cell-b1a9f3b61b943d80",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3ccdb36fd0eb01c7468d40a82106e52",
     "grade": true,
     "grade_id": "cell-a1f86e69911bce5e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sorted(d.keys()) == ['Expression', 'Facets', 'JobPositionPostings', 'TotalResultCount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f92c0f71550b9dbc5ff4f22c3982dff0",
     "grade": false,
     "grade_id": "cell-9e12252b918a6e96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "> **Ex. 6.1.3.:** Create a dataframe named `df` from the 'JobPositionPostings' field in the json object from the previous exercise.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e81368a2114c506a3d4d53dcaeaaaeb4",
     "grade": false,
     "grade_id": "cell-a39477579f548e6e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a724c520fdc9de52a2dc1e904d55529",
     "grade": true,
     "grade_id": "cell-7131e79791ea0e8c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sorted(df.columns) == ['Abroad', 'AnonymousEmployer', 'AssignmentStartDate', 'AutomatchType', 'Country', \n",
    "                              'DetailsUrl', 'EmploymentType', 'FormattedLastDateApplication', 'HasLocationValues', \n",
    "                              'HiringOrgCVR', 'HiringOrgName', 'ID', 'IsExternal', 'IsHotjob', 'JobAnnouncementType', \n",
    "                              'JobHeadline', 'JobLogUrl', 'JoblogWorkTime', 'LastDateApplication', 'Latitude', 'Location',\n",
    "                              'Longitude', 'Municipality', 'Occupation', 'OccupationArea', 'OccupationGroup', \n",
    "                              'OrganisationId', 'PostalCode', 'PostalCodeName', 'PostingCreated', 'Presentation',\n",
    "                              'Region', 'ShareUrl', 'Title', 'Url', 'UseWorkPlaceAddressForJoblog', 'UserLoggedIn',\n",
    "                              'Weight', 'WorkHours', 'WorkPlaceAbroad', 'WorkPlaceAddress', 'WorkPlaceCity',\n",
    "                              'WorkPlaceNotStatic', 'WorkPlaceOtherAddress', 'WorkPlacePostalCode', 'WorkplaceID']\n",
    "assert len(df) == 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d59d282f8c9b5701bb3385c04206ed03",
     "grade": false,
     "grade_id": "cell-83ba2d019cf2164a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Problems from Exercise Set 8\n",
    "\n",
    "> **Ex. 8.1.2:** From exercise 8.1.1 in Module 8 we found that the company `euphemia media` owns the domain \"netbaby.dk\". Now we want to gather further information about this company.\n",
    "\n",
    "> Go to the Central Business Register website https://datacvr.virk.dk/data/. Figure out how to look up companies by changing the url and then lookup `euphemia media`. Use `requests` to get the html and parse this with `BeautifulSoup`. Store the parsed html in the variable `soup`. Find the CVR number in the `soup`, store this in the variable `cvr` and finally print this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23f4b4f6f8bc4d73598cefe71ff07746",
     "grade": false,
     "grade_id": "cell-8ac57a7c29a7a9e5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff9f40cfd56c22b52ba325862a5a507b",
     "grade": true,
     "grade_id": "cell-fdedf045d58ac444",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import bs4; type(soup) == bs4.BeautifulSoup\n",
    "assert str(cvr) == '21848875'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
